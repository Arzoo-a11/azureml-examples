{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/machine-learning-pipelines/pipeline-style-transfer/pipeline-style-transfer-parallel-run.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural style transfer on video\n",
        "Using modified code from `pytorch`'s neural style [example](https://pytorch.org/tutorials/advanced/neural_style_tutorial.html), we show how to setup a pipeline for doing style transfer on video. The pipeline has following steps:\n",
        "1. Split a video into images\n",
        "2. Run neural style on each image using one of the provided models (from `pytorch` pretrained models for this example).\n",
        "3. Stitch the image back into a video.\n",
        "\n",
        "> **Tip**\n",
        "If your system requires low-latency processing (to process a single document or small set of documents quickly), use [real-time scoring](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-consume-web-service) instead of batch prediction."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first if you haven't. This sets you up with a working config file that has information on your workspace, subscription id, etc. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Workspace\n",
        "\n",
        "Initialize a workspace object from persisted configuration."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.20.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1618864328636
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: opendatasetspmworkspace2\n",
            "Azure region: eastus2\n",
            "Subscription id: 21d8f407-c4c4-452e-87a4-e609bfb86248\n",
            "Resource group: opendatasetspmrg\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1618864333302
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "from azureml.core import Datastore, Dataset\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.data import OutputFileDatasetConfig"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1618864333744
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# create directory for model\n",
        "model_dir = 'models'\n",
        "if not os.path.isdir(model_dir):\n",
        "    os.mkdir(model_dir)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1618864339902
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "def download_model(model_name):\n",
        "    # downloaded models from https://pytorch.org/tutorials/advanced/neural_style_tutorial.html are kept here\n",
        "    url = \"https://pipelinedata.blob.core.windows.net/styletransfer/saved_models/\" + model_name\n",
        "    local_path = os.path.join(model_dir, model_name)\n",
        "    urllib.request.urlretrieve(url, local_path)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1618864341597
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Register all Models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "mosaic_model = None\n",
        "candy_model = None\n",
        "\n",
        "models = Model.list(workspace=ws, tags=['scenario'])\n",
        "for m in models:\n",
        "    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)\n",
        "    if m.name == 'mosaic' and mosaic_model is None:\n",
        "        mosaic_model = m\n",
        "    elif m.name == 'candy' and candy_model is None:\n",
        "        candy_model = m\n",
        "\n",
        "if mosaic_model is None:\n",
        "    print('Mosaic model does not exist, registering it')\n",
        "    download_model('mosaic.pth')\n",
        "    mosaic_model = Model.register(model_path = os.path.join(model_dir, \"mosaic.pth\"),\n",
        "                       model_name = \"mosaic\",\n",
        "                       tags = {'type': \"mosaic\", 'scenario': \"Style transfer using batch inference\"},\n",
        "                       description = \"Style transfer - Mosaic\",\n",
        "                       workspace = ws)\n",
        "else:\n",
        "    print('Reusing existing mosaic model')\n",
        "    \n",
        "\n",
        "if candy_model is None:\n",
        "    print('Candy model does not exist, registering it')\n",
        "    download_model('candy.pth')\n",
        "    candy_model = Model.register(model_path = os.path.join(model_dir, \"candy.pth\"),\n",
        "                       model_name = \"candy\",\n",
        "                       tags = {'type': \"candy\", 'scenario': \"Style transfer using batch inference\"},\n",
        "                       description = \"Style transfer - Candy\",\n",
        "                       workspace = ws)\n",
        "else:\n",
        "    print('Reusing existing candy model')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mosaic model does not exist, registering it\n",
            "Registering model mosaic\n",
            "Candy model does not exist, registering it\n",
            "Registering model candy\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1618864353124
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create or use existing compute"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# AmlCompute\n",
        "cpu_cluster_name = \"cpu-cluster\"\n",
        "try:\n",
        "    cpu_cluster = AmlCompute(ws, cpu_cluster_name)\n",
        "    print(\"found existing cluster.\")\n",
        "except ComputeTargetException:\n",
        "    print(\"creating new cluster\")\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_v2\",\n",
        "                                                                    max_nodes = 1)\n",
        "\n",
        "    # create the cluster\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, provisioning_config)\n",
        "    cpu_cluster.wait_for_completion(show_output=True)\n",
        "    \n",
        "# AmlCompute\n",
        "gpu_cluster_name = \"gpu-cluster\"\n",
        "try:\n",
        "    gpu_cluster = AmlCompute(ws, gpu_cluster_name)\n",
        "    print(\"found existing cluster.\")\n",
        "except ComputeTargetException:\n",
        "    print(\"creating new cluster\")\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\",\n",
        "                                                                max_nodes = 3)\n",
        "\n",
        "    # create the cluster\n",
        "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, provisioning_config)\n",
        "    gpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a name for your cluster\r\n",
        "cpu_cluster_name = \"cpu-cluster\"\r\n",
        "\r\n",
        "found = False\r\n",
        "# Check if this compute target already exists in the workspace.\r\n",
        "cts = ws.compute_targets\r\n",
        "if cpu_cluster_name in cts and cts[cpu_cluster_name].type == 'AmlCompute':\r\n",
        "    found = True\r\n",
        "    print('Found existing compute target.')\r\n",
        "    compute_target = cts[cpu_cluster_name]\r\n",
        "    \r\n",
        "if not found:\r\n",
        "    print('Creating a new compute target...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_v2\", max_nodes = 1)\r\n",
        "\r\n",
        "    # Create the cluster.\r\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\r\n",
        "    cpu_cluster.wait_for_completion(show_output = True, min_node_count=None, timeout_in_minutes = 10)\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# AmlCompute\r\n",
        "gpu_cluster_name = \"gpu-cluster\"\r\n",
        "\r\n",
        "found = False\r\n",
        "# Check if this compute target already exists in the workspace.\r\n",
        "cts = ws.compute_targets\r\n",
        "if gpu_cluster_name in cts and cts[gpu_cluster_name].type == 'AmlCompute':\r\n",
        "    found = True\r\n",
        "    print('Found existing compute target.')\r\n",
        "    compute_target = cts[gpu_cluster_name]\r\n",
        "    \r\n",
        "if not found:\r\n",
        "    print('Creating a new compute target...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\", max_nodes = 3)\r\n",
        "\r\n",
        "    # Create the cluster.\r\n",
        "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\r\n",
        "    gpu_cluster.wait_for_completion(show_output = True, min_node_count=None, timeout_in_minutes = 10)\r\n",
        "    \r\n",
        "# For a more detailed view of current AmlCompute status, use get_status().print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute target.\n",
            "Found existing compute target.\n"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618869799896
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Scripts\n",
        "We use an edited version of `neural_style_mpi.py` (original is [here](https://github.com/pytorch/examples/blob/master/fast_neural_style/neural_style/neural_style.py)). Scripts to split and stitch the video are thin wrappers to calls to `ffmpeg`. \n",
        "\n",
        "We install `ffmpeg` through conda dependencies."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "scripts_folder = \"scripts\""
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1618868706054
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_video_script_file = \"process_video.py\"\n",
        "\n",
        "# peek at contents\n",
        "with open(os.path.join(scripts_folder, process_video_script_file)) as process_video_file:\n",
        "    print(process_video_file.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import argparse\n",
            "import glob\n",
            "import os\n",
            "import subprocess\n",
            "\n",
            "parser = argparse.ArgumentParser(description=\"Process input video\")\n",
            "parser.add_argument('--input_video', required=True)\n",
            "parser.add_argument('--output_audio', required=True)\n",
            "parser.add_argument('--output_images', required=True)\n",
            "\n",
            "args = parser.parse_args()\n",
            "\n",
            "os.makedirs(args.output_audio, exist_ok=True)\n",
            "os.makedirs(args.output_images, exist_ok=True)\n",
            "\n",
            "subprocess.run(\"ffmpeg -i {} {}/video.aac\".format(args.input_video, args.output_audio),\n",
            "               shell=True,\n",
            "               check=True)\n",
            "\n",
            "subprocess.run(\"ffmpeg -i {} {}/%05d_video.jpg -hide_banner\".format(args.input_video, args.output_images),\n",
            "               shell=True,\n",
            "               check=True)\n",
            "\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1618868707461
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stitch_video_script_file = \"stitch_video.py\"\n",
        "\n",
        "# peek at contents\n",
        "with open(os.path.join(scripts_folder, stitch_video_script_file)) as stitch_video_file:\n",
        "    print(stitch_video_file.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import argparse\n",
            "import os\n",
            "import subprocess\n",
            "\n",
            "parser = argparse.ArgumentParser(description=\"Process input video\")\n",
            "parser.add_argument('--images_dir', required=True)\n",
            "parser.add_argument('--input_audio', required=True)\n",
            "parser.add_argument('--output_dir', required=True)\n",
            "\n",
            "args = parser.parse_args()\n",
            "\n",
            "os.makedirs(args.output_dir, exist_ok=True)\n",
            "\n",
            "subprocess.run(\"ffmpeg -framerate 30 -i {}/%05d_video.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p \"\n",
            "               \"-y {}/video_without_audio.mp4\"\n",
            "               .format(args.images_dir, args.output_dir),\n",
            "               shell=True, check=True)\n",
            "\n",
            "subprocess.run(\"ffmpeg -i {}/video_without_audio.mp4 -i {}/video.aac -map 0:0 -map 1:0 -vcodec \"\n",
            "               \"copy -acodec copy -y {}/video_with_audio.mp4\"\n",
            "               .format(args.output_dir, args.input_audio, args.output_dir),\n",
            "               shell=True, check=True)\n",
            "\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1618868711789
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sample video **organutan.mp4** is stored at a publicly shared datastore. We are registering the datastore below. If you want to take a look at the original video, click here. (https://pipelinedata.blob.core.windows.net/sample-videos/orangutan.mp4)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# datastore for input video\n",
        "account_name = \"pipelinedata\"\n",
        "video_ds = Datastore.register_azure_blob_container(ws, \"videos\", \"sample-videos\",\n",
        "                                            account_name=account_name, overwrite=True)\n",
        "\n",
        "# the default blob store attached to a workspace\n",
        "default_datastore = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1618868718353
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample video"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "video_name=os.getenv(\"STYLE_TRANSFER_VIDEO_NAME\", \"orangutan.mp4\") \n",
        "orangutan_video = Dataset.File.from_files((video_ds,video_name))"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1618868726494
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd = CondaDependencies()\n",
        "\n",
        "cd.add_channel(\"conda-forge\")\n",
        "cd.add_conda_package(\"ffmpeg==4.0.2\")\n",
        "\n",
        "# Runconfig\n",
        "amlcompute_run_config = RunConfiguration(conda_dependencies=cd)\n",
        "amlcompute_run_config.environment.docker.base_image = \"pytorch/pytorch\"\n",
        "amlcompute_run_config.environment.spark.precache_packages = False"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1618868733020
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ffmpeg_audio = OutputFileDatasetConfig(name=\"ffmpeg_audio\")\n",
        "processed_images = OutputFileDatasetConfig(name=\"processed_images\")\n",
        "output_video = OutputFileDatasetConfig(name=\"output_video\")\n",
        "\n",
        "ffmpeg_images = OutputFileDatasetConfig(name=\"ffmpeg_images\")"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1618868734663
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define tweakable parameters to pipeline\n",
        "These parameters can be changed when the pipeline is published and rerun from a REST call.\n",
        "As part of ParallelRunStep following 2 pipeline parameters will be created which can be used to override values.\n",
        "    node_count\n",
        "    process_count_per_node"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.graph import PipelineParameter\n",
        "# create a parameter for style (one of \"candy\", \"mosaic\") to transfer the images to\n",
        "style_param = PipelineParameter(name=\"style\", default_value=\"mosaic\")\n",
        "# create a parameter for the number of nodes to use in step no. 2 (style transfer)\n",
        "nodecount_param = PipelineParameter(name=\"nodecount\", default_value=2)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1618868740841
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_video_step = PythonScriptStep(\n",
        "    name=\"split video\",\n",
        "    script_name=\"process_video.py\",\n",
        "    arguments=[\"--input_video\", orangutan_video.as_mount(),\n",
        "               \"--output_audio\", ffmpeg_audio,\n",
        "               \"--output_images\", ffmpeg_images],\n",
        "    compute_target=cpu_cluster,\n",
        "    runconfig=amlcompute_run_config,\n",
        "    source_directory=scripts_folder\n",
        ")\n",
        "\n",
        "stitch_video_step = PythonScriptStep(\n",
        "    name=\"stitch\",\n",
        "    script_name=\"stitch_video.py\",\n",
        "    arguments=[\"--images_dir\", processed_images.as_input(), \n",
        "               \"--input_audio\", ffmpeg_audio.as_input(), \n",
        "               \"--output_dir\", output_video],\n",
        "    compute_target=cpu_cluster,\n",
        "    runconfig=amlcompute_run_config,\n",
        "    source_directory=scripts_folder\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1618868742505
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create environment, parallel step run config and parallel run step"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
        "\n",
        "parallel_cd = CondaDependencies()\n",
        "\n",
        "parallel_cd.add_channel(\"pytorch\")\n",
        "parallel_cd.add_conda_package(\"pytorch\")\n",
        "parallel_cd.add_conda_package(\"torchvision\")\n",
        "parallel_cd.add_conda_package(\"pillow<7\") # needed for torchvision==0.4.0\n",
        "parallel_cd.add_pip_package(\"azureml-core\")\n",
        "\n",
        "styleenvironment = Environment(name=\"styleenvironment\")\n",
        "styleenvironment.python.conda_dependencies=parallel_cd\n",
        "styleenvironment.docker.base_image = DEFAULT_GPU_IMAGE"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1618870121547
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AmlCompute\r\n",
        "gpu_cluster_name = \"gpu-cluster\"\r\n",
        "\r\n",
        "found = False\r\n",
        "# Check if this compute target already exists in the workspace.\r\n",
        "cts = ws.compute_targets\r\n",
        "if gpu_cluster_name in cts and cts[gpu_cluster_name].type == 'AmlCompute':\r\n",
        "    found = True\r\n",
        "    print('Found existing compute target.')\r\n",
        "    compute_target = cts[gpu_cluster_name]\r\n",
        "    \r\n",
        "if not found:\r\n",
        "    print('Creating a new compute target...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_NC6\", max_nodes = 3)\r\n",
        "\r\n",
        "    # Create the cluster.\r\n",
        "    gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\r\n",
        "    gpu_cluster.wait_for_completion(show_output = True, min_node_count=None, timeout_in_minutes = 10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute target.\n"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618870125630
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineParameter\n",
        "from azureml.pipeline.steps import ParallelRunConfig\n",
        "\n",
        "parallel_run_config = ParallelRunConfig(\n",
        "    environment=styleenvironment,\n",
        "    entry_script='transform.py',\n",
        "    output_action='summary_only',\n",
        "    mini_batch_size=\"1\",\n",
        "    error_threshold=1,\n",
        "    source_directory=scripts_folder,\n",
        "    compute_target=gpu_cluster, \n",
        "    node_count=nodecount_param,\n",
        "    process_count_per_node=2\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gpu_cluster' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b24d135b5108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0merror_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msource_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscripts_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcompute_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_cluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnode_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodecount_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprocess_count_per_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gpu_cluster' is not defined"
          ]
        }
      ],
      "execution_count": 34,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunStep\n",
        "from datetime import datetime\n",
        "\n",
        "parallel_step_name = 'styletransfer-' + datetime.now().strftime('%Y%m%d%H%M')\n",
        "\n",
        "distributed_style_transfer_step = ParallelRunStep(\n",
        "    name=parallel_step_name,\n",
        "    inputs=[ffmpeg_images], # Input file share/blob container/file dataset\n",
        "    output=processed_images,  # Output file share/blob container\n",
        "    arguments=[\"--style\", style_param],\n",
        "    parallel_run_config=parallel_run_config,\n",
        "    allow_reuse=False #[optional - default value True]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(workspace=ws, steps=[stitch_video_step])\n",
        "\n",
        "pipeline.validate()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input input_0d2231f1 on step stitch is not connected to any previous step.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-539eb7cca1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstitch_video_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/_experiment_method.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \"\"\"\n\u001b[1;32m     96\u001b[0m             \u001b[0mExperimentSubmitRegistrar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_submit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parameter %s is not recognized for Pipeline '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_email_notification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menable_email_notification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_experiment_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, name, steps, finalize, regenerate_outputs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregenerate_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregenerate_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, name, steps)\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_builderStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_builderStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1540\u001b[0m         \u001b[0madded_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madded_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \"\"\"\n\u001b[1;32m   1829\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;31m# just a step?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipelineStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;31m# delegate to correct builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_step\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mresolved_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0;31m# resolve run_after's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mresolve_references\u001b[0;34m(self, node_list)\u001b[0m\n\u001b[1;32m   1685\u001b[0m                             \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Input '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_port\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' on step '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mparent_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m                                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is not connected to any previous step.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                                 raise ValueError('{} is connected to an invalid item: {}.'.format(\n",
            "\u001b[0;31mValueError\u001b[0m: Input input_0d2231f1 on step stitch is not connected to any previous step."
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# submit the pipeline and provide values for the PipelineParameters used in the pipeline\n",
        "pipeline_run = Experiment(ws, 'styletransfer_parallel_mosaic').submit(pipeline)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monitor pipeline run\n",
        "\n",
        "The pipeline run status could be checked in Azure Machine Learning portal (https://ml.azure.com). The link to the pipeline run could be retrieved by inspecting the `pipeline_run` object.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# This will output information of the pipeline run, including the link to the details page of portal.\n",
        "pipeline_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional: View detailed logs (streaming) "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Wait the run for completion and show output log to console\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download output video"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads the video in `output_video` folder"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def download_video(run, target_dir=None):\n",
        "    stitch_run = run.find_step_run(stitch_video_step.name)[0]\n",
        "    port_data = stitch_run.get_details()['outputDatasets'][0]['dataset']\n",
        "    port_data.download(target_dir)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run.wait_for_completion()\n",
        "download_video(pipeline_run, \"output_video_mosaic\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Publish pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_name = \"style-transfer-batch-inference\"\n",
        "print(pipeline_name)\n",
        "\n",
        "published_pipeline = pipeline.publish(\n",
        "    name=pipeline_name, \n",
        "    description=pipeline_name)\n",
        "print(\"Newly published pipeline id: {}\".format(published_pipeline.id))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get published pipeline\n",
        "This is another way to get the published pipeline."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PublishedPipeline\n",
        "\n",
        "# You could retrieve all pipelines that are published, or \n",
        "# just get the published pipeline object that you have the ID for.\n",
        "\n",
        "# Get all published pipeline objects in the workspace\n",
        "all_pub_pipelines = PublishedPipeline.list(ws)\n",
        "\n",
        "# We will iterate through the list of published pipelines and \n",
        "# use the last ID in the list for Schelue operations: \n",
        "print(\"Published pipelines found in the workspace:\")\n",
        "for pub_pipeline in all_pub_pipelines:\n",
        "    print(\"Name:\", pub_pipeline.name,\"\\tDescription:\", pub_pipeline.description, \"\\tId:\", pub_pipeline.id, \"\\tStatus:\", pub_pipeline.status)\n",
        "    if(pub_pipeline.name == pipeline_name):\n",
        "        published_pipeline = pub_pipeline\n",
        "\n",
        "print(\"Published pipeline id: {}\".format(published_pipeline.id))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run pipeline through REST calls for other styles\n",
        "\n",
        "# Get AAD token"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "import requests\n",
        "\n",
        "auth = InteractiveLoginAuthentication()\n",
        "aad_token = auth.get_authentication_header()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get endpoint URL"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rest_endpoint = published_pipeline.endpoint\n",
        "print(\"Pipeline REST endpoing: {}\".format(rest_endpoint))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Send request and monitor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'styletransfer_parallel_candy'\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=aad_token,\n",
        "                         json={\"ExperimentName\": experiment_name,\n",
        "                               \"ParameterAssignments\": {\"style\": \"candy\", \"NodeCount\": 3}})\n",
        "\n",
        "run_id = response.json()[\"Id\"]\n",
        "\n",
        "from azureml.pipeline.core.run import PipelineRun\n",
        "published_pipeline_run_candy = PipelineRun(ws.experiments[experiment_name], run_id)\n",
        "\n",
        "# Show detail information of run\n",
        "published_pipeline_run_candy"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download output from re-run"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline_run_candy.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "download_video(published_pipeline_run_candy, target_dir=\"output_video_candy\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "index_order": 1,
    "exclude_from_index": true,
    "task": "Style transfer",
    "deployment": [
      "None"
    ],
    "authors": [
      {
        "name": "sanpil joringer asraniwa pansav tracych"
      }
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "compute": [
      "AML Compute"
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "tags": [
      "Batch Inferencing",
      "Pipeline"
    ],
    "datasets": [],
    "category": "Other notebooks",
    "framework": [
      "None"
    ],
    "friendly_name": "Style transfer using ParallelRunStep",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}