{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Bring your own data (Part 3 of 3)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the previous [Tutorial: Train a model in the cloud](2.pytorch-model.ipynb) article, the CIFAR10 data was downloaded using the builtin `torchvision.datasets.CIFAR10` method in the PyTorch API. However, in many cases you are going to want to use your own data in a remote training run. This article focuses on the workflow you can leverage such that you can work with your own data in Azure Machine Learning. \n",
    "\n",
    "By the end of this tutorial you would have a better understanding of:\n",
    "\n",
    "- How to upload your data to Azure\n",
    "- Best practices for working with cloud data in Azure Machine Learning\n",
    "- Working with command-line arguments\n",
    "\n",
    "---\n",
    "\n",
    "## Your machine learning code\n",
    "\n",
    "By now you have your training script running in Azure Machine Learning, and can monitor the model performance. Let's _parametrize_ the training script by introducing\n",
    "arguments. Using arguments will allow you to easily compare different hyperparmeters.\n",
    "\n",
    "Presently our training script is set to download the CIFAR10 dataset on each run. The python code in [train-with-cloud-data-and-logging.py](src/train-with-cloud-data-and-logging.py) now uses **`argparse` to parametize the script.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding your machine learning code changes\n",
    "\n",
    "The script `train-with-cloud-data-and-logging.py` has leveraged the `argparse` library to set up the `--data-path`, `--learning-rate`, `--momentum`, and `--epochs` arguments:\n",
    "\n",
    "```python\n",
    "import argparse\n",
    "...\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data-path\", type=str, help=\"Path to the training data\")\n",
    "parser.add_argument(\"--learning-rate\", type=float, default=0.001, help=\"Learning rate for SGD\")\n",
    "parser.add_argument(\"--momentum\", type=float, default=0.9, help=\"Momentum for SGD\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=2, help=\"Number of epochs to train\")\n",
    "args = parser.parse_args()\n",
    "```\n",
    "\n",
    "The script was adapted to update the optimizer to use the user-defined parameters:\n",
    "\n",
    "```python\n",
    "optimizer = optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=args.learning_rate,     # get learning rate from command-line argument\n",
    "    momentum=args.momentum,    # get momentum from command-line argument\n",
    ")\n",
    "```\n",
    "\n",
    "Similarly the training loop was adapted to update the number of epochs to train to use the user-defined parameters:\n",
    "```python\n",
    "for epoch in range(args.epochs):\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload your data to Azure\n",
    "\n",
    "In order to run this script in Azure Machine Learning, you need to make your training data available in Azure. Your Azure Machine Learning workspace comes equipped with a _default_ **Datastore** - an Azure Blob storage account - that you can use to store your training data.\n",
    "\n",
    "> <span style=\"color:purple; font-weight:bold\">! NOTE <br>\n",
    "> Azure Machine Learning allows you to connect other cloud-based datastores that store your data. For more details, see [datastores documentation](./concept-data.md).</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.5.0-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\hancwang\\miniconda3\\envs\\v2-index\\lib\\site-packages (from torchvision) (1.15.0)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-8.1.0-cp38-cp38-win_amd64.whl (2.2 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.20.1-cp38-cp38-win_amd64.whl (13.7 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.2.2.post3-py2.py3-none-any.whl (64 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-1.7.1-cp38-cp38-win_amd64.whl (184.0 MB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: typing-extensions, numpy, torch, pillow, torchvision\n",
      "Successfully installed numpy-1.20.1 pillow-8.1.0 torch-1.7.1 torchvision-0.2.2.post3 typing-extensions-3.7.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading cifar-10-batches-py:   0%|                                                             | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Uploading cifar-10-batches-py:  12%|██████▌                                             | 1/8 [00:00<00:00, 502.97it/s]\u001b[A\n",
      "Uploading cifar-10-batches-py:  25%|█████████████▎                                       | 2/8 [00:21<01:05, 10.93s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  25%|█████████████▎                                       | 2/8 [00:21<01:05, 10.93s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  38%|███████████████████▉                                 | 3/8 [00:46<01:22, 16.59s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  38%|███████████████████▉                                 | 3/8 [00:46<01:22, 16.59s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  50%|██████████████████████████▌                          | 4/8 [01:10<01:17, 19.48s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  50%|██████████████████████████▌                          | 4/8 [01:10<01:17, 19.48s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  62%|█████████████████████████████████▏                   | 5/8 [01:32<01:00, 20.28s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  62%|█████████████████████████████████▏                   | 5/8 [01:32<01:00, 20.28s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  75%|███████████████████████████████████████▊             | 6/8 [01:55<00:42, 21.14s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  75%|███████████████████████████████████████▊             | 6/8 [01:55<00:42, 21.14s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py:  88%|██████████████████████████████████████████████▍      | 7/8 [01:55<00:21, 21.14s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py: 100%|█████████████████████████████████████████████████████| 8/8 [02:16<00:00, 16.02s/it]\u001b[A\n",
      "Uploading cifar-10-batches-py: 100%|█████████████████████████████████████████████████████| 8/8 [02:16<00:00, 17.08s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azure.ml._schema.asset.InternalAsset at 0x25cd2759ac0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscription_id = '5f08d643-1910-4a38-a7c7-84a39d4f42e0'\n",
    "resource_group = 'hanchi-test'\n",
    "workspace = 'hanchi-test'\n",
    "\n",
    "from torchvision import datasets\n",
    "from azure.ml import MLClient\n",
    "\n",
    "#datasets.CIFAR10(\".\", download=True)\n",
    "\n",
    "ml_client = MLClient(subscription_id, resource_group, workspace)\n",
    "\n",
    "ml_client.data.upload(name=\"cifar-10-batches\", version=1, local_path=\"cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "from torchvision import datasets\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "datasets.CIFAR10(\".\", download=True)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(\n",
    "    src_dir=\"cifar-10-batches-py\",\n",
    "    target_path=\"tutorials/datasets/cifar-10-batches-py\",\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "os.remove(\"cifar-10-python.tar.gz\")\n",
    "shutil.rmtree(\"cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `target_path` specifies the path on the datastore where the CIFAR10 data will be uploaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your machine learning code to Azure Machine Learning\n",
    "\n",
    "As you have done previously, create a new Python control script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeserializationError",
     "evalue": "Cannot deserialize content-type: text/html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDeserializationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-08b616cba988>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./job-cloud-data.yml\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workspace_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreturned_job\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_or_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_operations\\job_operations.py\u001b[0m in \u001b[0;36mcreate_or_update\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# Create all dependent resources\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_upload_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mgit_props\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_git_properties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop_value\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgit_props\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_operations\\job_operations.py\u001b[0m in \u001b[0;36m_upload_dependencies\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;31m# are required. Also consider the implications for dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mCommandJob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morchestrators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_code_asset_arm_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_environment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morchestrators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_environment_arm_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_environment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_operations\\operation_orchestrator.py\u001b[0m in \u001b[0;36mget_code_asset_arm_id\u001b[1;34m(self, code_asset, register_asset)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_asset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInternalCodeAsset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mregister_asset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcode_asset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_or_create_code_asset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_code_assets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muuid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_schema\\code_asset.py\u001b[0m in \u001b[0;36mcheck_or_create_code_asset\u001b[1;34m(self, code_operations)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m# Code resource IDs must be guids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muuid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mcode_artifact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcode_operations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcode_artifact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Cannot find resource for code asset: {str(path)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_operations\\code_operations.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name, directory, version, datastore_name, show_progress)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Version must be an integer value.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         artifact = _upload_to_datastore(\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workspace_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datastore_operation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_artifacts\\_artifact_utilities.py\u001b[0m in \u001b[0;36m_upload_to_datastore\u001b[1;34m(workspace_scope, datastore_operation, path, datastore_name, show_progress, include_container_in_asset_path, asset_name, asset_version)\u001b[0m\n\u001b[0;32m    110\u001b[0m ) -> AssetArtifact:\n\u001b[0;32m    111\u001b[0m     \u001b[0m_validate_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mdatastore_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatastore_name\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdatastore_operation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     \u001b[0mignore_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ignore_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0masset_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_object_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_operations\\datastore_operations.py\u001b[0m in \u001b[0;36mget_default\u001b[1;34m(self, include_secrets)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_secrets\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInternalADLSGen1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInternalAzureStorage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Returns the workspace's default datastore\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         ds = self._operation.list(\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workspace_scope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubscription_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workspace_scope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_group_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\core\\paging.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_page_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_page_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mby_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_page_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mnext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[1;31m# Python 2 compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\core\\paging.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"End of paging\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinuation_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAzureError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinuation_token\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_restclient\\machinelearningservices\\operations\\_datastores_operations.py\u001b[0m in \u001b[0;36mget_next\u001b[1;34m(next_link)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mErrorResponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m                 \u001b[0mmap_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mHttpResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mARMErrorFormat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\msrest\\serialization.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, target_obj, response_data, content_type)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDeserialized\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \"\"\"\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\msrest\\serialization.py\u001b[0m in \u001b[0;36m_unpack_content\u001b[1;34m(raw_data, content_type)\u001b[0m\n\u001b[0;32m   1537\u001b[0m         \u001b[1;31m#Assume this is enough to recognize universal_http.ClientResponse without importing it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1538\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"body\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1539\u001b[1;33m             return RawDeserializer.deserialize_from_http_generics(\n\u001b[0m\u001b[0;32m   1540\u001b[0m                 \u001b[0mraw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1541\u001b[0m                 \u001b[0mraw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\msrest\\pipeline\\universal.py\u001b[0m in \u001b[0;36mdeserialize_from_http_generics\u001b[1;34m(cls, body_bytes, headers)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbody_bytes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\msrest\\pipeline\\universal.py\u001b[0m in \u001b[0;36mdeserialize_from_text\u001b[1;34m(cls, data, content_type)\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[0m_LOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wasn't XML not JSON, failing\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[0mraise_with_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDeserializationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"XML is invalid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mDeserializationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot deserialize content-type: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDeserializationError\u001b[0m: Cannot deserialize content-type: text/html"
     ]
    }
   ],
   "source": [
    "from azure.ml.entities import Job\n",
    "\n",
    "job = Job.load(\"./job-cloud-data.yml\", ml_client._workspace_scope)\n",
    "returned_job = ml_client.jobs.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remote run",
     "batchai",
     "configure run",
     "use notebook widget",
     "get metrics",
     "use datastore"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import (\n",
    "    Experiment,\n",
    "    Environment,\n",
    "    ScriptRunConfig,\n",
    "    Dataset,\n",
    ")\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "ds = Dataset.File.from_files((ws.get_default_datastore(), \"tutorials/datasets/\"))\n",
    "env = Environment.from_conda_specification(\n",
    "    name=\"pytorch-env-tutorial\",\n",
    "    file_path=\"environment.yml\",\n",
    ")\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=\"src\",\n",
    "    script=\"train-with-cloud-data-and-logging.py\",\n",
    "    compute_target=\"cpu-cluster\",\n",
    "    environment=env,\n",
    "    arguments=[\n",
    "        \"--data-path\",\n",
    "        ds.as_mount(),\n",
    "        \"--learning-rate\",\n",
    "        0.003,\n",
    "        \"--momentum\",\n",
    "        0.92,\n",
    "        \"--epochs\",\n",
    "        2,\n",
    "    ],\n",
    ")\n",
    "\n",
    "run = Experiment(\n",
    "    workspace=ws, name=\"an-introduction-train-cloud-data-logging-tutorial\"\n",
    ").submit(src)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the control code\n",
    "\n",
    "The above control code has the following additional code compared to the control code written in [previous tutorial](2.pytorch-model.ipynb)\n",
    "\n",
    "**`ds = Dataset.File.from_files(path=(datastore, 'tutorials/datasets'))`**: A Dataset is used to reference the data you uploaded to the Azure Blob Store. Datasets are an abstraction layer on top of your data that are designed to improve reliability and trustworthiness.\n",
    "\n",
    "\n",
    "**`src = ScriptRunConfig(...)`**: We modified the `ScriptRunConfig` to include a list of arguments that will be passed into training script. We also specified `ds.as_mount()`, which means the directory specified will be _mounted_ to the compute target.\n",
    "\n",
    "## Inspect the 70_driver_log log file\n",
    "\n",
    "In the navigate to the 70_driver_log.txt file - you should see the following output:\n",
    "\n",
    "```\n",
    "Processing 'input'.\n",
    "Processing dataset FileDataset\n",
    "{\n",
    "  \"source\": [\n",
    "    \"('workspaceblobstore', 'datasets/cifar10')\"\n",
    "  ],\n",
    "  \"definition\": [\n",
    "    \"GetDatastoreFiles\"\n",
    "  ],\n",
    "  \"registration\": {\n",
    "    \"id\": \"XXXXX\",\n",
    "    \"name\": null,\n",
    "    \"version\": null,\n",
    "    \"workspace\": \"Workspace.create(name='XXXX', subscription_id='XXXX', resource_group='X')\"\n",
    "  }\n",
    "}\n",
    "Mounting input to /tmp/tmp9kituvp3.\n",
    "Mounted input to /tmp/tmp9kituvp3 as folder.\n",
    "Exit __enter__ of DatasetContextManager\n",
    "Entering Run History Context Manager.\n",
    "Current directory:  /mnt/batch/tasks/shared/LS_root/jobs/dsvm-aml/azureml/tutorial-session-3_1600171983_763c5381/mounts/workspaceblobstore/azureml/tutorial-session-3_1600171983_763c5381\n",
    "Preparing to call script [ train.py ] with arguments: ['--data_path', '$input', '--learning_rate', '0.003', '--momentum', '0.92']\n",
    "After variable expansion, calling script [ train.py ] with arguments: ['--data_path', '/tmp/tmp9kituvp3', '--learning_rate', '0.003', '--momentum', '0.92']\n",
    "\n",
    "Script type = None\n",
    "===== DATA =====\n",
    "DATA PATH: /tmp/tmp9kituvp3\n",
    "LIST FILES IN DATA PATH...\n",
    "['cifar-10-batches-py', 'cifar-10-python.tar.gz']\n",
    "```\n",
    "\n",
    "Notice:\n",
    "\n",
    "1. Azure Machine Learning has mounted the blob store to the compute cluster automatically for you\n",
    "2. The ``ds.as_mount()`` used in the control script resolves to the mount point\n",
    "3. In the machine learning code we include a line to list the directorys under the data directory - you can see the list above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not going to use what you've created here, delete the resources you just created with this quickstart so you don't incur any charges for storage. In the Azure portal, select and delete your resource group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: cc4af23f-b753-496c-a0bd-e4d37ae68fe1\n",
      "Web View: https://ml.azure.com/experiments/Default/runs/cc4af23f-b753-496c-a0bd-e4d37ae68fe1?wsid=/subscriptions/5f08d643-1910-4a38-a7c7-84a39d4f42e0/resourcegroups/hanchi-test/workspaces/hanchi-test\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: cc4af23f-b753-496c-a0bd-e4d37ae68fe1\n",
      "Web View: https://ml.azure.com/experiments/Default/runs/cc4af23f-b753-496c-a0bd-e4d37ae68fe1?wsid=/subscriptions/5f08d643-1910-4a38-a7c7-84a39d4f42e0/resourcegroups/hanchi-test/workspaces/hanchi-test\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"AmlComputeBadRequest\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"88bfd74b52a07de5\"\n    },\n    \"environment\": \"master\",\n    \"location\": \"westus2\",\n    \"time\": \"2021-02-23T07:41:11.242785Z\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-82ef2a2a7ad2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mml_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturned_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_operations\\job_operations.py\u001b[0m in \u001b[0;36mstream_logs\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m# This should be done lazily on the workspaceSScope and cached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_runs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_operation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_workspace_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream_logs_until_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_runs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs_only\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_path\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\v2-index\\lib\\site-packages\\azure\\ml\\_operations\\job_ops_helper.py\u001b[0m in \u001b[0;36mstream_logs_until_completion\u001b[1;34m(run_operations, job_resource, raise_exception_on_failed_job)\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[0mfile_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception : \\n {} \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mfile_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"AmlComputeBadRequest\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"88bfd74b52a07de5\"\n    },\n    \"environment\": \"master\",\n    \"location\": \"westus2\",\n    \"time\": \"2021-02-23T07:41:11.242785Z\"\n} "
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream_logs(returned_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "samkemp"
   }
  ],
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved. Licensed under the MIT License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
