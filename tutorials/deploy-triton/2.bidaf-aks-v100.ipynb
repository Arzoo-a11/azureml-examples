{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Triton Inference Server on AKS\n",
    "\n",
    "description: (preview) deploy a bi-directional attention flow (bidaf) Q&A model to V100s on AKS via Triton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this Public Preview release is subject to the [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nvidia-pyindex in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (1.0.5)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already up-to-date: tritonclient in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (2.6.0)\n",
      "Requirement already satisfied, skipping upgrade: python-rapidjson>=0.9.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from tritonclient) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.19.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from tritonclient) (1.19.4)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 2074k  100 2074k    0     0   673k      0  0:00:03  0:00:03 --:--:-- 1304k\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: azureml-core==1.19.0a1 from file:///home/gopalv/azureml-examples/tutorials/deploy-triton/azureml_core-1.19.0a1-py3-none-any.whl in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (1.19.0a1)\n",
      "Requirement already satisfied: msrestazure>=0.4.33 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.6.4)\n",
      "Requirement already satisfied: requests>=2.19.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.24.0)\n",
      "Requirement already satisfied: azure-mgmt-storage<16.0.0,>=1.5.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (11.1.0)\n",
      "Requirement already satisfied: azure-mgmt-authorization<1.0.0,>=0.40.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.60.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.15.35 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.15.89)\n",
      "Requirement already satisfied: backports.tempfile in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.0)\n",
      "Requirement already satisfied: urllib3>=1.23 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.25.10)\n",
      "Requirement already satisfied: azure-mgmt-resource<15.0.0,>=1.2.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (8.0.1)\n",
      "Requirement already satisfied: jsonpickle in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.4.1)\n",
      "Requirement already satisfied: msrest>=0.5.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.6.18)\n",
      "Requirement already satisfied: ndg-httpsclient in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.5.1)\n",
      "Requirement already satisfied: SecretStorage in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (3.1.2)\n",
      "Requirement already satisfied: adal>=1.2.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.2.4)\n",
      "Requirement already satisfied: pyopenssl<20.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (19.1.0)\n",
      "Requirement already satisfied: azure-mgmt-containerregistry>=2.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.8.0)\n",
      "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (3.0)\n",
      "Requirement already satisfied: jmespath in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.10.0)\n",
      "Requirement already satisfied: pytz in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2020.1)\n",
      "Requirement already satisfied: pathspec in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.8.0)\n",
      "Requirement already satisfied: docker in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (4.2.2)\n",
      "Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.61.1)\n",
      "Requirement already satisfied: azure-mgmt-keyvault<7.0.0,>=0.40.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.2.0)\n",
      "Requirement already satisfied: contextlib2 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (0.6.0.post1)\n",
      "Requirement already satisfied: azure-common>=1.1.12 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.1.25)\n",
      "Requirement already satisfied: PyJWT<2.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from azureml-core==1.19.0a1) (2.8.1)\n",
      "Requirement already satisfied: six in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from msrestazure>=0.4.33->azureml-core==1.19.0a1) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core==1.19.0a1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core==1.19.0a1) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core==1.19.0a1) (3.0.4)\n",
      "Requirement already satisfied: backports.weakref in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from backports.tempfile->azureml-core==1.19.0a1) (1.0.post1)\n",
      "Requirement already satisfied: importlib-metadata in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from jsonpickle->azureml-core==1.19.0a1) (1.7.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core==1.19.0a1) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core==1.19.0a1) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.1 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from ndg-httpsclient->azureml-core==1.19.0a1) (0.4.8)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from SecretStorage->azureml-core==1.19.0a1) (0.4.3)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.19.0a1) (1.14.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from docker->azureml-core==1.19.0a1) (0.57.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from importlib-metadata->jsonpickle->azureml-core==1.19.0a1) (3.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.19.0a1) (3.1.0)\n",
      "Requirement already satisfied: pycparser in /home/gopalv/miniconda3/envs/azureml/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.19.0a1) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-pyindex\n",
    "!pip install --upgrade tritonclient\n",
    "!curl -L https://aka.ms/azureml-core-1.19.a1 --output azureml_core-1.19.0a1-py3-none-any.whl\n",
    "!pip install azureml_core-1.19.0a1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n=============================\n== Triton Inference Server ==\n=============================\n\nNVIDIA Release 20.06 (build 13333626)\n\nCopyright (c) 2018-2020, NVIDIA CORPORATION.  All rights reserved.\n\nVarious files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\nNVIDIA modifications are covered by the license terms that apply to the underlying\nproject or file.\n\nNOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n   insufficient for the inference server.  NVIDIA recommends the use of the following flags:\n   nvidia-docker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 ...\n\n2021-01-16 00:21:23.572842: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\nI0116 00:21:23.611734 1 metrics.cc:184] found 1 GPUs supporting NVML metrics\nI0116 00:21:23.617109 1 metrics.cc:193]   GPU 0: Tesla V100-PCIE-16GB\nI0116 00:21:23.617751 1 server.cc:120] Initializing Triton Inference Server\nerror: creating server: Internal - failed to stat file /var/azureml-app/azureml-models/bidaf-9-tutorial/805/triton/triton\n\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Workspace.create(name='default', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='azureml-examples')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model\n",
    "\n",
    "It's important that your model have this directory structure for Triton Inference Server to be able to load it. [Read more about the directory structure that Triton expects](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/model_repository.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "successfully downloaded model: densenet_onnx\n",
      "successfully downloaded model: bidaf-9\n"
     ]
    }
   ],
   "source": [
    "from src.model_utils import download_triton_models, delete_triton_models\n",
    "from pathlib import Path\n",
    "\n",
    "prefix = Path(\".\")\n",
    "download_triton_models(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registering model bidaf-9-tutorial\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='default', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='azureml-examples'), name=bidaf-9-tutorial, id=bidaf-9-tutorial:805, version=805, tags={'area': 'Natural language processing', 'type': 'Question-answering'}, properties={})"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_path = prefix.joinpath(\"models\")\n",
    "\n",
    "model = Model.register(\n",
    "    model_path=model_path,\n",
    "    model_name=\"bidaf-9-tutorial\",\n",
    "    tags={\"area\": \"Natural language processing\", \"type\": \"Question-answering\"},\n",
    "    description=\"Question answering from ONNX model zoo\",\n",
    "    workspace=ws,\n",
    "    model_framework=Model.Framework.MULTI,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy webservice\n",
    "\n",
    "Deploy to a pre-created [AksCompute](https://docs.microsoft.com/python/api/azureml-core/azureml.core.compute.aks.akscompute?view=azure-ml-py#provisioning-configuration-agent-count-none--vm-size-none--ssl-cname-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--location-none--vnet-resourcegroup-name-none--vnet-name-none--subnet-name-none--service-cidr-none--dns-service-ip-none--docker-bridge-cidr-none--cluster-purpose-none--load-balancer-type-none-) named `aks-gpu-deploy`. For other options, see [our documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where?tabs=azcli).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running...............................................................................\n",
      "Failed\n",
      "Service deployment polling reached non-successful terminal state, current service state: Transitioning\n",
      "Operation ID: 7a9d54cf-35c3-494d-a552-4fb8c9a73ba0\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"KubernetesDeploymentFailed\",\n",
      "  \"statusCode\": 400,\n",
      "  \"message\": \"Kubernetes Deployment failed\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"CrashLoopBackOff\",\n",
      "      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: triton-bidaf-974043. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image nvcr.io/nvidia/tritonserver:20.06-py3 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"DeploymentFailed\",\n",
      "      \"message\": \"Your container endpoint is not available. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. [{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Successfully pulled image \\\\\\\"mcr.microsoft.com/azureml/dependency-unpacker:20201117\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:06Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:08Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:08Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulling\\\",\\\"Message\\\":\\\"Pulling image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:11Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Successfully pulled image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:23Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"Unhealthy\\\",\\\"Message\\\":\\\"Readiness probe failed: Get http://10.244.65.8:8000/v2/health/ready: dial tcp 10.244.65.8:8000: connect: connection refused\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:29Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container triton-bidaf-974043\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container triton-bidaf-974043\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Container image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\" already present on machine\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"BackOff\\\",\\\"Message\\\":\\\"Back-off restarting failed container\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:35Z\\\"}]\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Transitioning\nOperation ID: 7a9d54cf-35c3-494d-a552-4fb8c9a73ba0\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment failed\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: triton-bidaf-974043. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image nvcr.io/nvidia/tritonserver:20.06-py3 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Your container endpoint is not available. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. [{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Successfully pulled image \\\\\\\"mcr.microsoft.com/azureml/dependency-unpacker:20201117\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:06Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:08Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:08Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulling\\\",\\\"Message\\\":\\\"Pulling image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:11Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Successfully pulled image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:23Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"Unhealthy\\\",\\\"Message\\\":\\\"Readiness probe failed: Get http://10.244.65.8:8000/v2/health/ready: dial tcp 10.244.65.8:8000: connect: connection refused\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:29Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container triton-bidaf-974043\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container triton-bidaf-974043\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Container image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\" already present on machine\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"BackOff\\\",\\\"Message\\\":\\\"Back-off restarting failed container\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:35Z\\\"}]\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Transitioning\\nOperation ID: 7a9d54cf-35c3-494d-a552-4fb8c9a73ba0\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: triton-bidaf-974043. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image nvcr.io/nvidia/tritonserver:20.06-py3 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"DeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container endpoint is not available. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. [{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"mcr.microsoft.com/azureml/dependency-unpacker:20201117\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:06Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Created\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Created container amlappinit\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:08Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Started container amlappinit\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:08Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Pulling image \\\\\\\\\\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:11Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:23Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Warning\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Unhealthy\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Readiness probe failed: Get http://10.244.65.8:8000/v2/health/ready: dial tcp 10.244.65.8:8000: connect: connection refused\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:29Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Created\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Created container triton-bidaf-974043\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:30Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Started container triton-bidaf-974043\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:30Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Container image \\\\\\\\\\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\\\\\\\\\" already present on machine\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:30Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Warning\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"BackOff\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Back-off restarting failed container\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:35Z\\\\\\\"}]\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eb24f5a09a57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/azureml/lib/python3.7/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 915\u001b[0;31m                                                       logs_response, error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    916\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    917\u001b[0m                                                                                   operation_state))\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Transitioning\nOperation ID: 7a9d54cf-35c3-494d-a552-4fb8c9a73ba0\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment failed\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance: triton-bidaf-974043. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\nYou can also try to run image nvcr.io/nvidia/tritonserver:20.06-py3 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Your container endpoint is not available. Please follow the steps to debug:\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. [{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Successfully pulled image \\\\\\\"mcr.microsoft.com/azureml/dependency-unpacker:20201117\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:06Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:08Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:08Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulling\\\",\\\"Message\\\":\\\"Pulling image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:13:11Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Successfully pulled image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\"\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:23Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"Unhealthy\\\",\\\"Message\\\":\\\"Readiness probe failed: Get http://10.244.65.8:8000/v2/health/ready: dial tcp 10.244.65.8:8000: connect: connection refused\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:29Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container triton-bidaf-974043\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container triton-bidaf-974043\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Container image \\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\" already present on machine\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:30Z\\\"},{\\\"InvolvedObject\\\":\\\"triton-bidaf-974043-5954b7f879-spg4c\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"BackOff\\\",\\\"Message\\\":\\\"Back-off restarting failed container\\\",\\\"LastTimestamp\\\":\\\"2021-01-16T00:15:35Z\\\"}]\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Transitioning\\nOperation ID: 7a9d54cf-35c3-494d-a552-4fb8c9a73ba0\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\nPlease check the logs for your container instance: triton-bidaf-974043. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. \\\\nYou can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\nYou can also try to run image nvcr.io/nvidia/tritonserver:20.06-py3 locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"DeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container endpoint is not available. Please follow the steps to debug:\\\\n1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\\\n2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n3. View the diagnostic events to check status of container, it may help you to debug the issue. [{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"mcr.microsoft.com/azureml/dependency-unpacker:20201117\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:06Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Created\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Created container amlappinit\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:08Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Started container amlappinit\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:08Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Pulling image \\\\\\\\\\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:13:11Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:23Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Warning\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Unhealthy\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Readiness probe failed: Get http://10.244.65.8:8000/v2/health/ready: dial tcp 10.244.65.8:8000: connect: connection refused\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:29Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Created\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Created container triton-bidaf-974043\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:30Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Started container triton-bidaf-974043\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:30Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Normal\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Container image \\\\\\\\\\\\\\\"nvcr.io/nvidia/tritonserver:20.06-py3\\\\\\\\\\\\\\\" already present on machine\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:30Z\\\\\\\"},{\\\\\\\"InvolvedObject\\\\\\\":\\\\\\\"triton-bidaf-974043-5954b7f879-spg4c\\\\\\\",\\\\\\\"InvolvedKind\\\\\\\":\\\\\\\"Pod\\\\\\\",\\\\\\\"Type\\\\\\\":\\\\\\\"Warning\\\\\\\",\\\\\\\"Reason\\\\\\\":\\\\\\\"BackOff\\\\\\\",\\\\\\\"Message\\\\\\\":\\\\\\\"Back-off restarting failed container\\\\\\\",\\\\\\\"LastTimestamp\\\\\\\":\\\\\\\"2021-01-16T00:15:35Z\\\\\\\"}]\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from random import randint\n",
    "\n",
    "service_name = \"triton-bidaf-9\" + str(randint(10000, 99999))\n",
    "\n",
    "config = AksWebservice.deploy_configuration(\n",
    "    compute_target_name=\"aks-gpu-deploy\",\n",
    "    gpu_cores=1,\n",
    "    cpu_cores=1,\n",
    "    memory_gb=4,\n",
    "    auth_enabled=True,\n",
    ")\n",
    "\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=service_name,\n",
    "    models=[model],\n",
    "    deployment_config=config,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade nltk geventhttpclient python-rapidjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_key = service.get_keys()[0]\n",
    "scoring_uri = service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -v $scoring_uri/v2/health/ready -H 'Authorization: Bearer '\"$service_key\"''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Using a modified version of tritonhttpclient for Preview, PR is out for review\n",
    "# https://github.com/triton-inference-server/server/pull/2047\n",
    "import tritonclient.http as tritonhttpclient\n",
    "from tritonclientutils import triton_to_np_dtype\n",
    "\n",
    "from src.bidaf_utils import preprocess, postprocess\n",
    "\n",
    "key = service.get_keys()[0]\n",
    "headers = {}\n",
    "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "\n",
    "triton_client = tritonhttpclient.InferenceServerClient(service.scoring_uri[7:])\n",
    "\n",
    "context = \"A quick brown fox jumped over the lazy dog.\"\n",
    "query = \"Which animal was lower?\"\n",
    "\n",
    "model_name = \"bidaf-9\"\n",
    "\n",
    "model_metadata = triton_client.get_model_metadata(\n",
    "    model_name=model_name, headers=headers\n",
    ")\n",
    "\n",
    "input_meta = model_metadata[\"inputs\"]\n",
    "output_meta = model_metadata[\"outputs\"]\n",
    "\n",
    "# We use the np.object data type for string data\n",
    "np_dtype = triton_to_np_dtype(input_meta[0][\"datatype\"])\n",
    "cw, cc = preprocess(context, np_dtype)\n",
    "qw, qc = preprocess(query, np_dtype)\n",
    "\n",
    "input_mapping = {\n",
    "    \"query_word\": qw,\n",
    "    \"query_char\": qc,\n",
    "    \"context_word\": cw,\n",
    "    \"context_char\": cc,\n",
    "}\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# Populate the inputs array\n",
    "for in_meta in input_meta:\n",
    "    input_name = in_meta[\"name\"]\n",
    "    data = input_mapping[input_name]\n",
    "\n",
    "    input = tritonhttpclient.InferInput(input_name, data.shape, in_meta[\"datatype\"])\n",
    "\n",
    "    input.set_data_from_numpy(data, binary_data=False)\n",
    "    inputs.append(input)\n",
    "\n",
    "# Populate the outputs array\n",
    "for out_meta in output_meta:\n",
    "    output_name = out_meta[\"name\"]\n",
    "    output = tritonhttpclient.InferRequestedOutput(output_name, binary_data=False)\n",
    "    outputs.append(output)\n",
    "\n",
    "# Run inference\n",
    "res = triton_client.infer(\n",
    "    model_name,\n",
    "    inputs,\n",
    "    request_id=\"0\",\n",
    "    outputs=outputs,\n",
    "    model_version=\"1\",\n",
    "    headers=headers,\n",
    ")\n",
    "\n",
    "result = postprocess(context_words=cw, answer=res)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the webservice and the downloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service.delete()\n",
    "delete_triton_models(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "Try reading [our documentation](https://aka.ms/triton-aml-docs) to use Triton with your own models or check out the other notebooks in this folder for ways to do pre- and post-processing on the server. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "53514593536e52de022f29ef618678eddccd581b6db5dc532e9838fb19203af5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "name": "deploy-bidaf-aks",
  "task": "Use the high-performance Triton Inference Server with Azure Machine Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}