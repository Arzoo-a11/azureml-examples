{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Tutorial: Image Classification using Automated ML\n",
    "\n",
    "In this tutorial, you use automated machine learning in Azure Machine Learning service to  train an image classification model using the [MNIST](https://azure.microsoft.com/services/open-datasets/catalog/mnist/) dataset. This process accepts training data and configuration settings, and automatically iterates through combinations of different feature normalization/standardization methods, models, and hyperparameter settings to arrive at the best model.\n",
    "\n",
    "You will learn how to:\n",
    "\n",
    "> * Download a dataset and look at the data\n",
    "> * Train a machine learning image classification model using autoML \n",
    "> * Explore the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Connect to your workspace and create an experiment\n",
    "\n",
    "You start with importing some libraries and creating an experiment to track the runs in your workspace. A workspace can have multiple experiments, and all the users that have access to the workspace can collaborate on them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612475833739
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.interpret import ExplanationClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612475838758
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'mnist-automl-sdk'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Import Data\n",
    "\n",
    "Before you train a model, you need to understand the data that you are using to train it. In this section you will:\n",
    "\n",
    "* Download the MNIST dataset\n",
    "* Display some sample images\n",
    "\n",
    "### Download the MNIST dataset\n",
    "\n",
    "Use Azure Open Datasets to get the raw MNIST data files. [Azure Open Datasets](https://docs.microsoft.com/azure/open-datasets/overview-what-are-open-datasets) are curated public datasets that you can use to add scenario-specific features to machine learning solutions for more accurate models. Each dataset has a corrseponding class, `MNIST` in this case, to retrieve the data in different ways.\n",
    "\n",
    "Follow this [how-to](https://aka.ms/azureml/howto/createdatasets) if you want to learn more about Datasets and how to use them.\n",
    "\n",
    "To decide: should I add visualization of the data like in the other notebooks?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612475853636
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.opendatasets import MNIST\n",
    "\n",
    "mnist_dataset = MNIST.get_tabular_dataset()\n",
    "mnist_dataset_sample = mnist_dataset.take_sample(0.1,seed=42) # we will only download a small sample for this tutorial \n",
    "training_data, validation_data = mnist_dataset_sample.random_split(percentage=0.8, seed=223)\n",
    "label_column_name = 'label'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Train\n",
    "\n",
    "\n",
    "\n",
    "When you use automated machine learning in Azure ML, you input training data and configuration settings, and the process automatically iterates through combinations of different feature normalization/standardization methods, models, and hyperparameter settings to arrive at the best model. \n",
    "Learn more about how you configure automated ML [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train).\n",
    "\n",
    "\n",
    "Instantiate an [AutoMLConfig](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py) object. This defines the settings and data used to run the experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric**|This is the metric that you want to optimize. \n",
    "|**enable_early_stopping**  | Stop the run if the metric score is not showing improvement.|\n",
    "|**n_cross_validations**|Number of cross validation splits.|\n",
    "|**training_data**|Input dataset, containing both features and label column.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "\n",
    "You can find more information about primary metrics [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train#primary-metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612475861414
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"primary_metric\": 'accuracy',\n",
    "    \"experiment_timeout_hours\": 0.25, # This is a time limit for testing purposes, remove it for real use cases, this will drastically limit ability to find the best model possible\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"enable_stack_ensemble\": False\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             training_data = training_data,\n",
    "                             label_column_name = label_column_name,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Call the `submit` method on the experiment object and pass the run configuration. \n",
    "\n",
    "**Note: Depending on the data and the number of iterations an AutoML run can take a while to complete.**\n",
    "\n",
    "In this example, we specify `show_output = True` to print currently running iterations to the console. \n",
    "\n",
    "\n",
    "To be decided: what to show, this experience or the widget?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "local_run = experiment.submit(automl_config, show_output = False)\n",
    "# change to show_output=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612477139003
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Widget for Monitoring Runs\n",
    "\n",
    "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612477165504
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Analyze results\n",
    "\n",
    "Below we select the best model from our iterations. The `get_output` method on `automl_classifier` returns the best run and the model for the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612477186170
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run, best_model = local_run.get_output()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "\n",
    "Now that the model is trained, we'll run the test data through the trained model to get the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612477244718
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# convert the test data to dataframe\n",
    "X_test_df = validation_data.drop_columns(columns=[label_column_name]).to_pandas_dataframe()\n",
    "y_test_df = validation_data.keep_columns(columns=[label_column_name], validate=True).to_pandas_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612478501722
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# call the predict functions on the model\n",
    "y_pred = best_model.predict(X_test_df)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Calculate metrics for the prediction\n",
    "\n",
    "Now visualize the data to show what our truth (actual) values are compared to the predicted values \n",
    "from the trained model that was returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1612533265895
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "cf =confusion_matrix(y_test_df.values,y_pred)\n",
    "plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(np.arange(10), ('0,','1', '2', '3', '4', '5','6','7','8','9'))\n",
    "plt.yticks(np.arange(10), ('0,','1', '2', '3', '4', '5','6','7','8','9'))\n",
    "# plotting text value inside cells\n",
    "thresh = cf.max() / 2.\n",
    "for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n",
    "    plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Control cost and clean up resources\n",
    "\n",
    "To control cost and clean up the resources after this quickstart, there are several things you can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "\n",
    "\n",
    "If you want to control cost you can also stop the compute instance this notebook is running on by following these steps:\n",
    "\n",
    "1. Go to **Compute** in the left-hand menu of the Azure Machine Learning studio\n",
    "1. Select your compute instance\n",
    "1. Select **Stop**\n",
    "\n",
    "\n",
    "**Important: The resources you created can be used as prerequisites to other Azure Machine Learning tutorials and how-to articles.** If you don't plan to use the resources you created, delete them, so you don't incur any charges:\n",
    "\n",
    "1. In the Azure portal, select **Resource groups** on the far left.\n",
    "1. From the list, select the resource group you created.\n",
    "1. Select **Delete resource group**.\n",
    "1. Enter the resource group name. Then select **Delete**.\n",
    "\n",
    "You can also keep the resource group but delete a single workspace. Display the workspace properties and select **Delete**.\n",
    "\n",
    "To be decided: Should these instructions really be a part of the tutorials in this experience? What are the consequences of removing them? "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
